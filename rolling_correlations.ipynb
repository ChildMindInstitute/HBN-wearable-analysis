{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "rolling_correlation.py\n",
    "\n",
    "Functions to calculate and plot rolling correlation values pairwise between\n",
    "wearable device data streams.\n",
    "\n",
    "Created on Fri Apr 21 16:28:13 2017\n",
    "\n",
    "@author: jon.clucas\n",
    "\"\"\"\n",
    "from config import organized_dir\n",
    "from datetime import datetime, timedelta\n",
    "from plot_normalized_vector_lengths import baseshift_and_renormalize\n",
    "import os, pandas as pd, sys\n",
    "precision_dict = {'year':-6, 'month':-5, 'week': -4, 'day': -3, 'hour':-2,\n",
    "                  'minute':-1, 'second':0, 'decisecond':1, 'centisecond':2,\n",
    "                  'millisecond':3, 'microsecond':4, 'nanosecond':5,\n",
    "                  'picosecond':6}\n",
    "\n",
    "def only_matching_ts_points(s0, s1, precision='second'):\n",
    "    \"\"\"\n",
    "    Function to match time-series data streams point for point to the lowest\n",
    "    resolution.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    s0 : pandas dataframe\n",
    "        time-series data stream\n",
    "        \n",
    "    s1 : pandas dataframe\n",
    "        time-series data stream\n",
    "        \n",
    "    precision : int or string\n",
    "        if int, the number of decimal places of a fractional second; if string,\n",
    "        the time unit of resolution to match to.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    m0: pandas dataframe\n",
    "        time-series data with precision matching m2\n",
    "    \n",
    "    m1 : pandas dataframe\n",
    "        time-series data with precision matching m1\n",
    "    \"\"\"\n",
    "    if isinstance(precision, str):\n",
    "        precision = int(precision_dict[precision])\n",
    "    if precision < 0:\n",
    "        sys.exit(\"Matching precision less than second is not yet implemented\")\n",
    "    m0 = combine_extra_precision(s0, precision)\n",
    "    m1 = combine_extra_precision(s1, precision)\n",
    "    return(m0, m1)\n",
    "    \n",
    "def combine_extra_precision(df, decimals):\n",
    "    \"\"\"\n",
    "    Function to combine precision beyond the comparable limit.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        time series data\n",
    "        \n",
    "    decimals : int\n",
    "        the number of decimal places of a fractional second to include\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas dataframe\n",
    "        time series data with resolution reduced to specified level of\n",
    "        precision\n",
    "    \"\"\"\n",
    "    if(decimals == 0):\n",
    "        df[['Timestamp']] = df.Timestamp.apply(lambda x: datetime(x.year,\n",
    "                            x.month, x.day, x.hour, x.minute, x.second))\n",
    "    else:\n",
    "        df[['Timestamp']] = df.Timestamp.apply(lambda x: datetime(x.year,\n",
    "                            x.month, x.day, x.hour, x.minute, x.second,\n",
    "                            x.microsecond.round(decimals)))\n",
    "    df = pd.DataFrame(df.groupby(by='Timestamp')[list(df.columns)[1]].mean())\n",
    "    return(df)\n",
    "\n",
    "def r_corr(devices, sensor, start, stop):\n",
    "    \"\"\"\n",
    "    Function to calculate rolling correlations between two sensor data streams.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    devices : list of strings (len 2)\n",
    "        each string is the name of one of the two devices to compare\n",
    "        \n",
    "    sensor : string\n",
    "        the sensor to compare\n",
    "        \n",
    "    start : datetime\n",
    "        beginning of time to compare\n",
    "        \n",
    "    stop : datetime\n",
    "        end of time to compare\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ?\n",
    "    \"\"\"\n",
    "    if sensor == 'accelerometer':\n",
    "        suffix = '_normalized_unit.csv'\n",
    "    else:\n",
    "        suffix = '.csv'\n",
    "    s0 = pd.read_csv(os.path.join(organized_dir, sensor, ''.join([devices[0],\n",
    "         suffix])), usecols=['Timestamp', 'normalized_vector_length'],\n",
    "         parse_dates=['Timestamp'], infer_datetime_format=True)\n",
    "    s0 = s0.loc[(s0['Timestamp'] >= start) & (s0['Timestamp'] <= stop)].copy()\n",
    "    s1 = pd.read_csv(os.path.join(organized_dir, sensor, ''.join([devices[1],\n",
    "         suffix])), usecols=['Timestamp', 'normalized_vector_length'],\n",
    "         parse_dates=['Timestamp'], infer_datetime_format=True)\n",
    "    s1 = s1.loc[(s1['Timestamp'] >= start) & (s1['Timestamp'] <= stop)].copy()\n",
    "    # m0, m1 = only_matching_ts_points(s0, s1, 'second')\n",
    "    s0 = baseshift_and_renormalize(s0)\n",
    "    s1 = baseshift_and_renormalize(s1)\n",
    "    s1[['Timestamp']] = s1.Timestamp.apply(lambda x: x - timedelta(microseconds\n",
    "                        =1000))\n",
    "    s0.set_index('Timestamp', inplace=True)\n",
    "    s1.set_index('Timestamp', inplace=True)\n",
    "    df = s0.merge(s1, left_index=True, right_index=True, suffixes=(''.join([\n",
    "         '_', devices[0]]), ''.join(['_', devices[1]])))\n",
    "    correls = df.rolling(window=180, center=True).corr()\n",
    "    print(correls.loc[:, list(df.columns)[0], list(df.columns)[1]].dropna(\n",
    "          ).mean())\n",
    "    correls.loc[:, list(df.columns)[0], list(df.columns)[1]].plot()\n",
    "    # df.rolling(window=2, center=True).corr().sum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_corr(['GENEActiv_pink', 'Actigraph'], 'accelerometer',  datetime(2017, 4, 6,\n",
    "       15, 45), datetime(2017, 4, 7, 14, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thirty minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_corr(['GENEActiv_pink', 'Actigraph'], 'accelerometer',  datetime(2017, 4, 7,\n",
    "       7, 15), datetime(2017, 4, 7, 7, 45))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
